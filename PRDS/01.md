Product Requirements Document (PRD): Telequery AI
Version: 1.1
Date: July 14, 2025
Author: Gemini

1. Overview & Vision
Vision: To transform a user's Telegram message history from a simple archive into an interactive, intelligent, and searchable knowledge base. Users should be able to converse with their own data, asking complex questions and receiving synthesized, context-aware answers without manually sifting through thousands of messages.

Problem: Telegram is a hub for personal, social, and professional conversations. Over time, valuable information, decisions, and memories get buried in long chat histories. Finding specific information is often difficult, relying on basic keyword searches that lack contextual understanding.

Solution: We will create Telequery AI, a sophisticated, standalone query interface module written in Python. This module connects to a pre-populated SQLite database of a user's Telegram messages and leverages a Large Language Model (LLM) to understand and answer natural language questions. It acts as a personal intelligence assistant for a user's Telegram life, exposing its functionality via a clear API.

Scope: This project is concerned only with the Telequery AI module. The custom client responsible for gathering messages and populating the database is considered a separate component.

2. Target Audience
Primary: Individual Telegram power-users who are part of numerous active groups (e.g., project teams, social clubs, event planning groups, large family chats) and need an efficient way to recall information.

Secondary: Developers who want to integrate this query capability into custom Telegram bots or other applications via its API.

3. Technology Stack
Language: Python 3.10+

API Framework: FastAPI (for its high performance and native Pydantic integration).

Core Logic: A custom Pydantic-based agent loop for structured, validated data flow and tool execution.

Database: SQLite (for storing and accessing the Telegram message data).

LLM Integration: An LLM-agnostic wrapper library will be used to ensure flexibility and allow for easy switching between models (e.g., from OpenAI, Anthropic, Google, or local models).

Semantic Search: A vector index library (e.g., FAISS, ChromaDB) will be used to create and query vector embeddings for the search_relevant_messages tool.

4. Core Features & Functionality
4.1. Pydantic Agent Architecture
The entire logic will be encapsulated in an agent built around Pydantic models. This ensures that all inputs, outputs, and tool interactions are strongly typed, validated, and predictable, reducing errors and improving maintainability.

4.2. Semantic Message Search (The "Tool")
The agent's primary tool will be search_relevant_messages.

Functionality: This tool takes a user's query and searches the SQLite database. The search must be semantic, not just keyword-based, finding conceptually related messages.

Input:

query_text: (string) The user's question.

chat_id: (string/int, optional) The specific chat/group to search within.

time_range: (tuple[datetime, datetime], optional) A time filter.

user_id: (string/int, optional) To filter messages from a specific user.

Output: A list of the most relevant message objects.

4.3. LLM-Powered Synthesis & Answering
Once the tool returns relevant context, the agent passes this context and the original question to the configured LLM via the abstraction layer.

Behavior:

Synthesizes a concise answer based only on the provided message context.

Cites sources by referencing the key messages used.

Clearly states when it cannot find an answer; it will not hallucinate.

5. API for Bot Integration
Telequery AI will expose a RESTful API built with FastAPI.

5.1. Health Check Endpoint
Endpoint: GET /status

Description: A simple endpoint to verify that the API is running and can connect to its dependencies (like the database).

Response (200 OK):

{
  "status": "ok",
  "version": "1.1"
}

5.2. Query Endpoint
Endpoint: POST /query

Description: The main endpoint for submitting user questions.

Request Body (JSON):

{
  "user_question": "who takes care of electricity for the camp?",
  "telegram_user_id": "user12345",
  "telegram_chat_id": "group-98765"
}

Response Body (JSON):

{
  "answer_text": "It appears that Alice (@alice_tg) is responsible for the electricity. She mentioned on June 28th that she would be bringing the main generator and coordinating the power grid.",
  "source_messages": [
    {
      "message_id": "msg_abcde",
      "sender": "Alice",
      "timestamp": "2025-06-28T14:30:00Z",
      "text": "Hey everyone, just confirming I've got the main generator covered for our camp's electricity. I'll map out the power grid plan this weekend."
    }
  ],
  "status": "success"
}

6. User Flow
User: Asks the Telegram bot, "who takes care of electricity?".

Telegram Bot: Forwards the question to the Telequery AI POST /query endpoint.

Telequery AI (Agent):
a. Receives and validates the request using Pydantic models.
b. Decides to use the search_relevant_messages tool.
c. Calls the tool with the query and chat_id.

Vector Index: The semantic search function queries the index and returns relevant message IDs.

SQLite DB: The tool retrieves the full message objects from the database.

Telequery AI (Agent):
a. Constructs a prompt for the LLM with the question and context.
b. Sends the prompt to the LLM via the agnostic wrapper.

LLM: Generates a synthesized answer.

Telequery AI: Formats the final JSON response and sends it back to the bot.

Telegram Bot: Displays the answer_text to the user.

7. Success Metrics
Response Relevance: Percentage of answers rated as "helpful" by the user.

API Latency: Average response time for the /query endpoint.

API Uptime: Percentage of successful requests to /status and /query.

Error Rate: Percentage of queries that result in a server error or a "could not find an answer" response.

8. Future Enhancements
Multi-Tool Agents: Add tools like summarize_chat or identify_key_decisions.

Proactive Intelligence: Allow the agent to proactively surface information.

Multi-modal Search: Extend search to include images and documents.
