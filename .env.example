# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: openai, anthropic
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Database Configuration
# For Docker: Use container paths (host ../telequery_db is mounted to /app/data)
DATABASE_URL=sqlite:///../telequery_db/telegram_messages.db
MAIN_DB_PATH=/app/data/telegram_messages.db
EXPANSION_DB_PATH=/app/data/telequery_expansions.db
VECTOR_INDEX_PATH=/app/data/message_embeddings.index

# ChromaDB Configuration  
CHROMA_DB_PATH=/app/data/chroma_db

# Docker Configuration
# When using Docker, the container mounts ../telequery_db to /app/data
# The MAIN_DB_PATH and container paths will be used automatically

# Optional: Logfire Configuration
# LOGFIRE_TOKEN=your-logfire-token-here
# LOGFIRE_CONSOLE=true
# ENVIRONMENT=development